{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8m-seg.pt\")  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.76 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.70  Python-3.8.19 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=yolov8m-seg.pt, data=seg_config.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\segment\\train8\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5162498  ultralytics.nn.modules.head.Segment          [6, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27,243,122 parameters, 27,243,106 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\.conda\\envs\\VisualInspection\\lib\\site-packages\\ultralytics\\engine\\trainer.py:268: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Repositorio_Belyeud\\Visual_Inspection\\archivos\\labels... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<00:00, 48.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Repositorio_Belyeud\\Visual_Inspection\\archivos\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Repositorio_Belyeud\\Visual_Inspection\\archivos\\labels.cache... 2 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\segment\\train8\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\segment\\train8\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.48G      2.097      4.491      3.511      2.268         90        640: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2         36     0.0085      0.222    0.00889     0.0013      0.385       0.25     0.0784     0.0253\n",
      "\n",
      "1 epochs completed in 0.002 hours.\n",
      "Optimizer stripped from runs\\segment\\train8\\weights\\last.pt, 54.8MB\n",
      "Optimizer stripped from runs\\segment\\train8\\weights\\best.pt, 54.8MB\n",
      "\n",
      "Validating runs\\segment\\train8\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.70  Python-3.8.19 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27,225,858 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2         36     0.0085      0.222    0.00889     0.0012      0.385       0.25     0.0783     0.0253\n",
      "                   0.1          2          6     0.0172      0.333     0.0141    0.00198      0.116        0.5      0.186     0.0404\n",
      "                   0.2          2          6          0          0          0          0      0.054      0.167     0.0922     0.0484\n",
      "                   0.5          2          6      0.018        0.5     0.0151    0.00281      0.139      0.833      0.152     0.0468\n",
      "                   1.0          2          6          0          0          0          0          1          0          0          0\n",
      "                   2.0          2          6     0.0158        0.5     0.0241    0.00241          0          0     0.0396     0.0164\n",
      "                   5.0          2          6          0          0          0          0          1          0          0          0\n",
      "Speed: 2.0ms preprocess, 43.3ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\segment\\train8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "results = model.train(data=\"seg_config.yaml\", epochs=1, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Environment\\TNC\\CNM\\Visual_Coin_Inspection\\nb\\..\\data\\labeled\\project-5-at-2024-07-08-22-27-03d581a0\\images\\0d46e198-IMG-20240703-WA0086.jpg: 640x480 (no detections), 27.0ms\n",
      "Speed: 4.0ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mruns\\segment\\train32\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: '0.1', 1: '0.2', 2: '0.5', 3: '1.0', 4: '2.0', 5: '5.0'}\n",
       " obb: None\n",
       " orig_img: array([[[29, 15, 16],\n",
       "         [28, 14, 15],\n",
       "         [26, 12, 13],\n",
       "         ...,\n",
       "         [20,  5,  9],\n",
       "         [20,  5,  9],\n",
       "         [20,  5,  9]],\n",
       " \n",
       "        [[32, 18, 19],\n",
       "         [30, 16, 17],\n",
       "         [28, 14, 15],\n",
       "         ...,\n",
       "         [20,  5,  9],\n",
       "         [20,  5,  9],\n",
       "         [20,  5,  9]],\n",
       " \n",
       "        [[36, 22, 23],\n",
       "         [34, 20, 21],\n",
       "         [30, 16, 17],\n",
       "         ...,\n",
       "         [20,  5,  9],\n",
       "         [20,  5,  9],\n",
       "         [20,  5,  9]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[33, 12, 14],\n",
       "         [32, 11, 13],\n",
       "         [31, 10, 12],\n",
       "         ...,\n",
       "         [33, 20, 18],\n",
       "         [33, 20, 18],\n",
       "         [33, 20, 18]],\n",
       " \n",
       "        [[33, 12, 14],\n",
       "         [33, 12, 14],\n",
       "         [32, 11, 13],\n",
       "         ...,\n",
       "         [33, 20, 18],\n",
       "         [33, 20, 18],\n",
       "         [32, 19, 17]],\n",
       " \n",
       "        [[33, 12, 14],\n",
       "         [33, 12, 14],\n",
       "         [33, 12, 14],\n",
       "         ...,\n",
       "         [33, 20, 18],\n",
       "         [32, 19, 17],\n",
       "         [32, 19, 17]]], dtype=uint8)\n",
       " orig_shape: (4160, 3112)\n",
       " path: 'c:\\\\Environment\\\\TNC\\\\CNM\\\\Visual_Coin_Inspection\\\\nb\\\\..\\\\data\\\\labeled\\\\project-5-at-2024-07-08-22-27-03d581a0\\\\images\\\\0d46e198-IMG-20240703-WA0086.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\segment\\\\train32'\n",
       " speed: {'preprocess': 4.04810905456543, 'inference': 27.02474594116211, 'postprocess': 1.5037059783935547}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model('../data/labeled/project-5-at-2024-07-08-22-27-03d581a0/images/0d46e198-IMG-20240703-WA0086.jpg', save=True)  # predict on an image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.19 ('VisualInspection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "2be6fb9c1ea88ee5b7106e7034eeaaaf878d80ea07396b34068c3854e0d364da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
